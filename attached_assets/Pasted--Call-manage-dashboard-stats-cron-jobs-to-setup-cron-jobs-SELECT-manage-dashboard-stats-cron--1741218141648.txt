
-- Call manage_dashboard_stats_cron_jobs() to setup cron jobs
SELECT manage_dashboard_stats_cron_jobs();

-- Function to update specific user's statistics 
CREATE OR REPLACE FUNCTION update_user_stats(p_user_id integer)
RETURNS void AS $$
BEGIN
    WITH user_stats AS (
        SELECT 
            u.id as user_id,
            COUNT(DISTINCT kb.id) as total_knowledge_base_count,
            COUNT(DISTINCT f.id) as total_file_count,
            COALESCE(SUM(f.file_size), 0) as total_storage_used,
            MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
        FROM users u
        LEFT JOIN files f ON f.user_id = u.id
        LEFT JOIN knowledge_base kb ON kb.file_id = f.id
        WHERE u.id = p_user_id
        GROUP BY u.id
    )
    INSERT INTO dashboard_stats (
        user_id,
        total_knowledge_base_count,
        total_file_count,
        total_storage_used,
        last_activity_date
    )
    SELECT * FROM user_stats
    ON CONFLICT (user_id) WHERE user_id IS NOT NULL
    DO UPDATE SET
        total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
        total_file_count = EXCLUDED.total_file_count,
        total_storage_used = EXCLUDED.total_storage_used,
        last_activity_date = EXCLUDED.last_activity_date,
        last_updated = CURRENT_TIMESTAMP;
END;
$$ LANGUAGE plpgsql;

-- Function to update specific organization's statistics
CREATE OR REPLACE FUNCTION update_organization_stats(p_organization_id integer)
RETURNS void AS $$
BEGIN
    WITH org_stats AS (
        SELECT 
            o.id as organization_id,
            COUNT(DISTINCT kb.id) as total_knowledge_base_count,
            COUNT(DISTINCT f.id) as total_file_count,
            COALESCE(SUM(f.file_size), 0) as total_storage_used,
            MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
        FROM organizations o
        LEFT JOIN files f ON f.organization_id = o.id
        LEFT JOIN knowledge_base kb ON kb.file_id = f.id
        WHERE o.id = p_organization_id
        GROUP BY o.id
    )
    INSERT INTO dashboard_stats (
        organization_id,
        total_knowledge_base_count,
        total_file_count,
        total_storage_used,
        last_activity_date
    )
    SELECT * FROM org_stats
    ON CONFLICT (organization_id) WHERE organization_id IS NOT NULL
    DO UPDATE SET
        total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
        total_file_count = EXCLUDED.total_file_count,
        total_storage_used = EXCLUDED.total_storage_used,
        last_activity_date = EXCLUDED.last_activity_date,
        last_updated = CURRENT_TIMESTAMP;
END;
$$ LANGUAGE plpgsql;]
(Background on this error at: https://sqlalche.me/e/20/f405)
ERROR:    Traceback (most recent call last):
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 521, in _prepare_and_execute
    prepared_stmt, attributes = await adapt_connection._prepare(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 768, in _prepare
    prepared_stmt = await self._connection.prepare(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/asyncpg/connection.py", line 635, in prepare
    return await self._prepare(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/asyncpg/connection.py", line 653, in _prepare
    stmt = await self._get_statement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/asyncpg/connection.py", line 432, in _get_statement
    statement = await self._protocol.prepare(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "asyncpg/protocol/protocol.pyx", line 165, in prepare
asyncpg.exceptions.PostgresSyntaxError: cannot insert multiple commands into a prepared statement

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 942, in do_execute
    cursor.execute(statement, parameters)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 580, in execute
    self._adapt_connection.await_(
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.ProgrammingError: <class 'asyncpg.exceptions.PostgresSyntaxError'>: cannot insert multiple commands into a prepared statement

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/starlette/routing.py", line 692, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/contextlib.py", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/fastapi/routing.py", line 133, in merged_lifespan
    async with original_context(app) as maybe_original_state:
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/contextlib.py", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/fastapi/routing.py", line 133, in merged_lifespan
    async with original_context(app) as maybe_original_state:
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/contextlib.py", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/fastapi/routing.py", line 133, in merged_lifespan
    async with original_context(app) as maybe_original_state:
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/contextlib.py", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/fastapi/routing.py", line 133, in merged_lifespan
    async with original_context(app) as maybe_original_state:
  File "/nix/store/clx0mcir7qw8zk36zbr4jra789g3knf6-python3-3.11.10/lib/python3.11/contextlib.py", line 210, in __aenter__
    return await anext(self.gen)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/fastapi/routing.py", line 133, in merged_lifespan
    async with original_context(app) as maybe_original_state:
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/starlette/routing.py", line 569, in __aenter__
    await self._router.startup()
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/starlette/routing.py", line 669, in startup
    await handler()
  File "/home/runner/workspace/app/main.py", line 137, in startup_event
    await create_tables()
  File "/home/runner/workspace/app/database/database_factory.py", line 75, in create_tables
    await init_database_procedures()
  File "/home/runner/workspace/app/database/database_factory.py", line 49, in init_database_procedures
    await execute_sql_file(session, str(sql_file))
  File "/home/runner/workspace/app/database/database_factory.py", line 24, in execute_sql_file
    await session.execute(text(sql))
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/ext/asyncio/session.py", line 463, in execute
    result = await greenlet_spawn(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py", line 201, in greenlet_spawn
    result = context.throw(*sys.exc_info())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2365, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2260, in _execute_internal
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1416, in execute
    return meth(
           ^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 516, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 942, in do_execute
    cursor.execute(statement, parameters)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 580, in execute
    self._adapt_connection.await_(
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py", line 132, in await_only
    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py", line 196, in greenlet_spawn
    value = await result
            ^^^^^^^^^^^^
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 558, in _prepare_and_execute
    self._handle_exception(error)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 508, in _handle_exception
    self._adapt_connection._handle_exception(error)
  File "/home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py", line 792, in _handle_exception
    raise translated_error from error
sqlalchemy.exc.ProgrammingError: (sqlalchemy.dialects.postgresql.asyncpg.ProgrammingError) <class 'asyncpg.exceptions.PostgresSyntaxError'>: cannot insert multiple commands into a prepared statement
[SQL: -- Create indexes for better query performance if they don't exist
CREATE INDEX IF NOT EXISTS idx_files_user_id ON files(user_id);
CREATE INDEX IF NOT EXISTS idx_files_organization_id ON files(organization_id);
CREATE INDEX IF NOT EXISTS idx_knowledge_base_file_id ON knowledge_base(file_id);
CREATE INDEX IF NOT EXISTS idx_user_organizations_user_id ON user_organizations(user_id);
CREATE INDEX IF NOT EXISTS idx_user_organizations_organization_id ON user_organizations(organization_id);

-- Create materialized view for user statistics if it doesn't exist
CREATE MATERIALIZED VIEW IF NOT EXISTS mv_user_stats AS
SELECT 
    u.id as user_id,
    COUNT(DISTINCT kb.id) as total_knowledge_base_count,
    COUNT(DISTINCT f.id) as total_file_count,
    COALESCE(SUM(f.file_size), 0) as total_storage_used,
    MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
FROM users u
LEFT JOIN files f ON f.user_id = u.id
LEFT JOIN knowledge_base kb ON kb.file_id = f.id
GROUP BY u.id;

-- Create materialized view for organization statistics if it doesn't exist
CREATE MATERIALIZED VIEW IF NOT EXISTS mv_organization_stats AS
SELECT 
    o.id as organization_id,
    COUNT(DISTINCT kb.id) as total_knowledge_base_count,
    COUNT(DISTINCT f.id) as total_file_count,
    COALESCE(SUM(f.file_size), 0) as total_storage_used,
    MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
FROM organizations o
LEFT JOIN files f ON f.organization_id = o.id
LEFT JOIN knowledge_base kb ON kb.file_id = f.id
GROUP BY o.id;

-- Function to refresh materialized views
CREATE OR REPLACE FUNCTION refresh_dashboard_stats_views()
RETURNS void AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_user_stats;
    REFRESH MATERIALIZED VIEW CONCURRENTLY mv_organization_stats;
END;
$$ LANGUAGE plpgsql;

-- Function to update dashboard statistics using materialized views
CREATE OR REPLACE FUNCTION update_dashboard_stats(batch_size integer DEFAULT 1000)
RETURNS void AS $$
DECLARE
    user_cursor CURSOR FOR 
        SELECT user_id, total_knowledge_base_count, total_file_count, 
               total_storage_used, last_activity_date 
        FROM mv_user_stats;
    org_cursor CURSOR FOR 
        SELECT organization_id, total_knowledge_base_count, total_file_count, 
               total_storage_used, last_activity_date 
        FROM mv_organization_stats;
    batch_counter integer := 0;
BEGIN
    -- Process user statistics in batches
    FOR user_stat IN user_cursor LOOP
        INSERT INTO dashboard_stats (
            user_id,
            total_knowledge_base_count,
            total_file_count,
            total_storage_used,
            last_activity_date
        ) VALUES (
            user_stat.user_id,
            user_stat.total_knowledge_base_count,
            user_stat.total_file_count,
            user_stat.total_storage_used,
            user_stat.last_activity_date
        )
        ON CONFLICT (user_id) WHERE user_id IS NOT NULL
        DO UPDATE SET
            total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
            total_file_count = EXCLUDED.total_file_count,
            total_storage_used = EXCLUDED.total_storage_used,
            last_activity_date = EXCLUDED.last_activity_date,
            last_updated = CURRENT_TIMESTAMP;

        batch_counter := batch_counter + 1;
        IF batch_counter >= batch_size THEN
            batch_counter := 0;
            COMMIT;
        END IF;
    END LOOP;

    -- Process organization statistics in batches
    batch_counter := 0;
    FOR org_stat IN org_cursor LOOP
        INSERT INTO dashboard_stats (
            organization_id,
            total_knowledge_base_count,
            total_file_count,
            total_storage_used,
            last_activity_date
        ) VALUES (
            org_stat.organization_id,
            org_stat.total_knowledge_base_count,
            org_stat.total_file_count,
            org_stat.total_storage_used,
            org_stat.last_activity_date
        )
        ON CONFLICT (organization_id) WHERE organization_id IS NOT NULL
        DO UPDATE SET
            total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
            total_file_count = EXCLUDED.total_file_count,
            total_storage_used = EXCLUDED.total_storage_used,
            last_activity_date = EXCLUDED.last_activity_date,
            last_updated = CURRENT_TIMESTAMP;

        batch_counter := batch_counter + 1;
        IF batch_counter >= batch_size THEN
            batch_counter := 0;
            COMMIT;
        END IF;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- Function to manage cron jobs
CREATE OR REPLACE FUNCTION manage_dashboard_stats_cron_jobs()
RETURNS void AS $$
BEGIN
    -- Check if pg_cron extension is available
    IF EXISTS (
        SELECT 1 
        FROM pg_extension 
        WHERE extname = 'pg_cron'
    ) THEN
        -- Add refresh_views_hourly job
        IF NOT EXISTS (
            SELECT 1 FROM cron.job 
            WHERE jobname = 'refresh_views_hourly'
        ) THEN
            INSERT INTO cron.job (jobname, schedule, command, nodename, nodeport, database, username)
            VALUES (
                'refresh_views_hourly',
                '*/30 * * * *',
                'SELECT refresh_dashboard_stats_views()',
                'localhost',
                5432,
                current_database(),
                current_user
            );
            RAISE NOTICE 'Created refresh_views_hourly job';
        END IF;

        -- Add update_stats_hourly job
        IF NOT EXISTS (
            SELECT 1 FROM cron.job 
            WHERE jobname = 'update_stats_hourly'
        ) THEN
            INSERT INTO cron.job (jobname, schedule, command, nodename, nodeport, database, username)
            VALUES (
                'update_stats_hourly',
                '0 * * * *',
                'SELECT update_dashboard_stats(1000)',
                'localhost',
                5432,
                current_database(),
                current_user
            );
            RAISE NOTICE 'Created update_stats_hourly job';
        END IF;

        RAISE NOTICE 'Dashboard stats cron jobs have been configured successfully';
    ELSE
        RAISE WARNING 'pg_cron extension is not available. Cron jobs were not scheduled.';
    END IF;
EXCEPTION WHEN OTHERS THEN
    RAISE WARNING 'Error managing cron jobs: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Call manage_dashboard_stats_cron_jobs() to setup cron jobs
SELECT manage_dashboard_stats_cron_jobs();

-- Function to update specific user's statistics 
CREATE OR REPLACE FUNCTION update_user_stats(p_user_id integer)
RETURNS void AS $$
BEGIN
    WITH user_stats AS (
        SELECT 
            u.id as user_id,
            COUNT(DISTINCT kb.id) as total_knowledge_base_count,
            COUNT(DISTINCT f.id) as total_file_count,
            COALESCE(SUM(f.file_size), 0) as total_storage_used,
            MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
        FROM users u
        LEFT JOIN files f ON f.user_id = u.id
        LEFT JOIN knowledge_base kb ON kb.file_id = f.id
        WHERE u.id = p_user_id
        GROUP BY u.id
    )
    INSERT INTO dashboard_stats (
        user_id,
        total_knowledge_base_count,
        total_file_count,
        total_storage_used,
        last_activity_date
    )
    SELECT * FROM user_stats
    ON CONFLICT (user_id) WHERE user_id IS NOT NULL
    DO UPDATE SET
        total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
        total_file_count = EXCLUDED.total_file_count,
        total_storage_used = EXCLUDED.total_storage_used,
        last_activity_date = EXCLUDED.last_activity_date,
        last_updated = CURRENT_TIMESTAMP;
END;
$$ LANGUAGE plpgsql;

-- Function to update specific organization's statistics
CREATE OR REPLACE FUNCTION update_organization_stats(p_organization_id integer)
RETURNS void AS $$
BEGIN
    WITH org_stats AS (
        SELECT 
            o.id as organization_id,
            COUNT(DISTINCT kb.id) as total_knowledge_base_count,
            COUNT(DISTINCT f.id) as total_file_count,
            COALESCE(SUM(f.file_size), 0) as total_storage_used,
            MAX(GREATEST(kb.updated_at, f.updated_at)) as last_activity_date
        FROM organizations o
        LEFT JOIN files f ON f.organization_id = o.id
        LEFT JOIN knowledge_base kb ON kb.file_id = f.id
        WHERE o.id = p_organization_id
        GROUP BY o.id
    )
    INSERT INTO dashboard_stats (
        organization_id,
        total_knowledge_base_count,
        total_file_count,
        total_storage_used,
        last_activity_date
    )
    SELECT * FROM org_stats
    ON CONFLICT (organization_id) WHERE organization_id IS NOT NULL
    DO UPDATE SET
        total_knowledge_base_count = EXCLUDED.total_knowledge_base_count,
        total_file_count = EXCLUDED.total_file_count,
        total_storage_used = EXCLUDED.total_storage_used,
        last_activity_date = EXCLUDED.last_activity_date,
        last_updated = CURRENT_TIMESTAMP;
END;
$$ LANGUAGE plpgsql;]
(Background on this error at: https://sqlalche.me/e/20/f405)